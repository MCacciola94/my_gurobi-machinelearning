{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial example using pytorch\n",
    "\n",
    "In this example, we redo the [adversarial example](https://gurobi-optimization-ml2gurobi.readthedocs-hosted.com/en/latest/examples/adversarial_mnist.html) of the documentation but use pytorch for training the neural network.\n",
    "\n",
    "We don't detail the optimization model here. Please refer to the example in the documentation.\n",
    "\n",
    "This example requires the additional packages:\n",
    " - [torch](https://pytorch.org/)\n",
    " - [torchvision](https://pytorch.org/)\n",
    " - [matplotlib](https://matplotlib.org/)\n",
    " - [skorch](https://skorch.readthedocs.io/en/stable/)\n",
    "\n",
    " The latter package is a wrapper for giving to pytorch a Scikit-Learn like interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary packages and load data\n",
    "\n",
    "We import all the package we need for this example.\n",
    "We fetch the MINST data set using sklearn's functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "import gurobipy as gp\n",
    "\n",
    "from gurobi_ml import add_predictor_constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./Datset/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 32134499.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Datset/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ./Datset/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./Datset/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 1803392.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Datset/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ./Datset/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./Datset/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 10800713.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Datset/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ./Datset/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./Datset/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 8366503.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Datset/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./Datset/MNIST/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get MNIST digit recognition data set\n",
    "mnist_train = torchvision.datasets.MNIST(root=\"../Datset/MNIST\", train=True, download=True)\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(root=\"./Datset/MNIST\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.flatten(mnist_train.data.type(torch.FloatTensor), start_dim=1)\n",
    "y_train = mnist_train.targets\n",
    "x_test = torch.flatten(mnist_test.data.type(torch.FloatTensor), start_dim=1)\n",
    "y_test = mnist_test.targets\n",
    "\n",
    "x_train /= 255.0  # scaling\n",
    "x_test /= 255.0  # scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct and train the neural network\n",
    "\n",
    "We construct a sequential neural network with 2 hidden layers of 50 neurons.\n",
    "To train it, we use `skorch` that provides an interface similar to `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28 * 28, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 10),\n",
    "    torch.nn.Softmax(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.loss.NLLLoss"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = NeuralNetClassifier(\n",
    "    nn_model,\n",
    "    max_epochs=5,\n",
    "    lr=0.1,\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "clf.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.0185\u001b[0m       \u001b[32m0.9587\u001b[0m        \u001b[35m0.2128\u001b[0m  0.9665\n",
      "      2        \u001b[36m0.0178\u001b[0m       \u001b[32m0.9606\u001b[0m        \u001b[35m0.2076\u001b[0m  0.9479\n",
      "      3        0.0180       0.9603        0.2107  0.9188\n",
      "      4        \u001b[36m0.0174\u001b[0m       0.9605        0.2126  0.9828\n",
      "      5        \u001b[36m0.0173\u001b[0m       0.9593        0.2132  0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Sequential(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=10, bias=True)\n",
       "    (5): Softmax(dim=1)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.loss.NLLLoss"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.1\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.optimizer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9796\n",
      "Validation set score: 0.9626\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training score: {clf.score(x_train, y_train):.4}\")\n",
    "print(f\"Validation set score: {clf.score(x_test, y_test):.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_regression = torch.nn.Sequential(*nn_model[:-1])\n",
    "nn_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6b9833b9a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageno = 10000\n",
    "image = mnist_train.data[imageno, :]\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_prob = nn_regression.forward(x_train[imageno, :])\n",
    "sorted_labels = torch.argsort(ex_prob)\n",
    "right_label = sorted_labels[-1]\n",
    "wrong_label = sorted_labels[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_prob.detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for sequential:\n",
      "200 variables\n",
      "110 constraints\n",
      "100 general constraints\n",
      "Input has shape (1, 784)\n",
      "Output has shape (1, 10)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Layer           Output Shape    Variables              Constraints              \n",
      "                                                Linear    Quadratic      General\n",
      "================================================================================\n",
      "linear_0             (1, 50)           50           50            0            0\n",
      "\n",
      "relu_1               (1, 50)           50            0            0           50\n",
      "\n",
      "linear_2             (1, 50)           50           50            0            0\n",
      "\n",
      "relu_3               (1, 50)           50            0            0           50\n",
      "\n",
      "linear_4             (1, 10)            0           10            0            0\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "image = x_train[imageno, :].numpy()  # We need numpy converted image\n",
    "\n",
    "m = gp.Model()\n",
    "delta = 5\n",
    "\n",
    "x = m.addMVar(image.shape, lb=0.0, ub=1.0, name=\"x\")\n",
    "y = m.addMVar(ex_prob.detach().numpy().shape, lb=-gp.GRB.INFINITY, name=\"y\")\n",
    "\n",
    "abs_diff = m.addMVar(image.shape, lb=0, ub=1, name=\"abs_diff\")\n",
    "\n",
    "m.setObjective(y[wrong_label] - y[right_label], gp.GRB.MAXIMIZE)\n",
    "\n",
    "# Bound on the distance to example in norm-1\n",
    "m.addConstr(abs_diff >= x - image)\n",
    "m.addConstr(abs_diff >= -x + image)\n",
    "m.addConstr(abs_diff.sum() <= delta)\n",
    "\n",
    "pred_constr = add_predictor_constr(m, nn_regression, x, y)\n",
    "\n",
    "pred_constr.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter BestBdStop to value 0\n",
      "Set parameter BestObjStop to value 0\n",
      "Gurobi Optimizer version 10.0.1 build v10.0.1rc0 (linux64)\n",
      "\n",
      "CPU model: AMD EPYC 7402 24-Core Processor, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 48 physical cores, 96 logical processors, using up to 32 threads\n",
      "\n",
      "Optimize a model with 1679 rows, 1778 columns and 46230 nonzeros\n",
      "Model fingerprint: 0xd037b8f4\n",
      "Model has 100 general constraints\n",
      "Variable types: 1778 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-06, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [4e-03, 5e+00]\n",
      "Presolve removed 1110 rows and 589 columns\n",
      "Presolve time: 0.20s\n",
      "Presolved: 569 rows, 1189 columns, 43591 nonzeros\n",
      "Variable types: 1118 continuous, 71 integer (71 binary)\n",
      "\n",
      "Root relaxation: objective 6.820081e+02, 477 iterations, 0.01 seconds (0.03 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  682.00809    0   50          -  682.00809      -     -    0s\n",
      "     0     0  611.10530    0   47          -  611.10530      -     -    0s\n",
      "     0     0  599.77933    0   54          -  599.77933      -     -    0s\n",
      "     0     0  598.28577    0   53          -  598.28577      -     -    0s\n",
      "     0     0  405.53460    0   55          -  405.53460      -     -    1s\n",
      "     0     0  405.53460    0   54          -  405.53460      -     -    1s\n",
      "     0     0  405.53460    0   53          -  405.53460      -     -    1s\n",
      "     0     0  405.53460    0   54          -  405.53460      -     -    1s\n",
      "     0     0  370.83412    0   50          -  370.83412      -     -    1s\n",
      "     0     0  356.58548    0   51          -  356.58548      -     -    1s\n",
      "     0     0  353.20975    0   51          -  353.20975      -     -    1s\n",
      "     0     0  352.32224    0   52          -  352.32224      -     -    1s\n",
      "     0     0  352.17479    0   51          -  352.17479      -     -    1s\n",
      "     0     0  272.89744    0   49          -  272.89744      -     -    1s\n",
      "     0     0  260.79635    0   48          -  260.79635      -     -    1s\n",
      "     0     0  260.10856    0   50          -  260.10856      -     -    1s\n",
      "     0     0  259.26538    0   50          -  259.26538      -     -    1s\n",
      "     0     0  259.05265    0   50          -  259.05265      -     -    1s\n",
      "     0     0  237.58289    0   48          -  237.58289      -     -    1s\n",
      "     0     0  236.58866    0   48          -  236.58866      -     -    1s\n",
      "     0     0  236.31799    0   48          -  236.31799      -     -    1s\n",
      "     0     0  217.03436    0   48          -  217.03436      -     -    1s\n",
      "     0     0  216.43111    0   48          -  216.43111      -     -    1s\n",
      "     0     0  216.32946    0   48          -  216.32946      -     -    1s\n",
      "     0     0  135.85228    0   48          -  135.85228      -     -    1s\n",
      "     0     0  134.73588    0   49          -  134.73588      -     -    1s\n",
      "     0     0  134.62657    0   50          -  134.62657      -     -    1s\n",
      "     0     0  131.08700    0   49          -  131.08700      -     -    1s\n",
      "     0     0  130.82885    0   48          -  130.82885      -     -    1s\n",
      "     0     0  127.04432    0   50          -  127.04432      -     -    2s\n",
      "H    0     0                     -21.2788903  127.04432   697%     -    2s\n",
      "     0     0  127.04432    0   50  -21.27889  127.04432   697%     -    2s\n",
      "     0     2  127.04432    0   50  -21.27889  127.04432   697%     -    2s\n",
      "*  972   771              39     -15.0720591   52.16104   446%  46.7    3s\n",
      "* 1040   786              38     -13.6727128   52.16104   481%  45.6    3s\n",
      "* 1176   834              41      -9.8845221   52.16104   628%  44.5    3s\n",
      "* 1182   834              41      -9.6073029   52.16104   643%  44.5    3s\n",
      "H 2335  1149                      -9.6055117   49.01529   610%  41.9    4s\n",
      "  3519  1256     cutoff   20        -9.60551   30.57260   418%  41.4    5s\n",
      "* 4032  1297              36      -8.2413375   30.14799   466%  40.9    5s\n",
      "* 7926   736              36      -8.1183524    0.86334   111%  40.6    8s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 20\n",
      "  Implied bound: 13\n",
      "  MIR: 103\n",
      "  Flow cover: 81\n",
      "  Relax-and-lift: 3\n",
      "\n",
      "Explored 8480 nodes (341239 simplex iterations) in 9.04 seconds (13.08 work units)\n",
      "Thread count was 32 (of 96 available processors)\n",
      "\n",
      "Solution count 8: -8.11835 -8.24134 -9.60551 ... -21.2789\n",
      "\n",
      "Optimization achieved user objective limit\n",
      "Best objective -8.118352365815e+00, best bound -1.842804134002e+00, gap 77.3008%\n"
     ]
    }
   ],
   "source": [
    "m.Params.BestBdStop = 0.0\n",
    "m.Params.BestObjStop = 0.0\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No counter example exists in neighborhood.\n"
     ]
    }
   ],
   "source": [
    "if m.ObjVal > 0.0:\n",
    "    plt.imshow(x.X.reshape((28, 28)), cmap=\"gray\")\n",
    "    x_input = torch.tensor(x.X.reshape(1, -1), dtype=torch.float32)\n",
    "    label = torch.argmax(nn_model.forward(x_input))\n",
    "    print(f\"Solution is classified as {label}\")\n",
    "else:\n",
    "    print(\"No counter example exists in neighborhood.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copyright © 2022 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfMIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "license": {
   "full_text": "# Copyright © 2022 Gurobi Optimization, LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================="
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
