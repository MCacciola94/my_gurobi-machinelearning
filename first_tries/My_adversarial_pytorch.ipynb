{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial example using pytorch\n",
    "\n",
    "In this example, we redo the [adversarial example](https://gurobi-optimization-ml2gurobi.readthedocs-hosted.com/en/latest/examples/adversarial_mnist.html) of the documentation but use pytorch for training the neural network.\n",
    "\n",
    "We don't detail the optimization model here. Please refer to the example in the documentation.\n",
    "\n",
    "This example requires the additional packages:\n",
    " - [torch](https://pytorch.org/)\n",
    " - [torchvision](https://pytorch.org/)\n",
    " - [matplotlib](https://matplotlib.org/)\n",
    " - [skorch](https://skorch.readthedocs.io/en/stable/)\n",
    "\n",
    " The latter package is a wrapper for giving to pytorch a Scikit-Learn like interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary packages and load data\n",
    "\n",
    "We import all the package we need for this example.\n",
    "We fetch the MINST data set using sklearn's functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "import gurobipy as gp\n",
    "\n",
    "from gurobi_ml import add_predictor_constr\n",
    "\n",
    "from base_trainer import trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 2\n",
    "batch_size=128\n",
    "lr =0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST digit recognition data set\n",
    "mnist_train = torchvision.datasets.MNIST(root=\"../Dataset/MNIST\", train=True,transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]), download=True)\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(root=\"../Dataset/MNIST\", train=False,transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ]), download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,batch_size=batch_size,\n",
    "                                           shuffle=True,)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,batch_size=batch_size,\n",
    "                                           shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct and train the neural network\n",
    "\n",
    "We construct a sequential neural network with 2 hidden layers of 50 neurons.\n",
    "To train it, we use `skorch` that provides an interface similar to `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28 * 28, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 10),\n",
    "    torch.nn.Softmax(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffgf\n",
      "epoch 1/2, loss = -0.1022\n",
      "epoch 1/2, loss = -0.1046\n",
      "epoch 1/2, loss = -0.1008\n",
      "epoch 1/2, loss = -0.1004\n",
      "epoch 1/2, loss = -0.1026\n",
      "epoch 2/2, loss = -0.1022\n",
      "epoch 2/2, loss = -0.1009\n",
      "epoch 2/2, loss = -0.1037\n",
      "epoch 2/2, loss = -0.1022\n",
      "epoch 2/2, loss = -0.1012\n"
     ]
    }
   ],
   "source": [
    "clf = trainer(\n",
    "    nn_model,\n",
    "    max_epochs=max_epochs,\n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "clf.fit(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model[0].weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.01333\n",
      "Validation set score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training score: {clf.score(train_loader):.4}\")\n",
    "print(f\"Validation set score: {clf.score(test_loader):.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_regression = torch.nn.Sequential(*nn_model[:-1]).cpu()\n",
    "nn_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe86965c490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageno = 10000\n",
    "image = mnist_train.data[imageno, :]\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_img = image.reshape(-1,28*28).type(torch.float32).squeeze(0)\n",
    "ex_prob = nn_regression.forward(flat_img)\n",
    "sorted_labels = torch.argsort(ex_prob)\n",
    "right_label = sorted_labels[-1]\n",
    "wrong_label = sorted_labels[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_prob.detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2024-10-28\n",
      "Model for sequential:\n",
      "200 variables\n",
      "110 constraints\n",
      "100 general constraints\n",
      "Input has shape (1, 784)\n",
      "Output has shape (1, 10)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Layer           Output Shape    Variables              Constraints              \n",
      "                                                Linear    Quadratic      General\n",
      "================================================================================\n",
      "linear_0             (1, 50)           50           50            0            0\n",
      "\n",
      "relu_1               (1, 50)           50            0            0           50\n",
      "\n",
      "linear_2             (1, 50)           50           50            0            0\n",
      "\n",
      "relu_3               (1, 50)           50            0            0           50\n",
      "\n",
      "linear_4             (1, 10)            0           10            0            0\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "image = flat_img.numpy()  # We need numpy converted image\n",
    "\n",
    "m = gp.Model()\n",
    "delta = 5\n",
    "\n",
    "x = m.addMVar(image.shape, lb=0.0, ub=1.0, name=\"x\")\n",
    "y = m.addMVar(ex_prob.detach().numpy().shape, lb=-gp.GRB.INFINITY, name=\"y\")\n",
    "\n",
    "abs_diff = m.addMVar(image.shape, lb=0, ub=1, name=\"abs_diff\")\n",
    "\n",
    "m.setObjective(y[wrong_label] - y[right_label], gp.GRB.MAXIMIZE)\n",
    "\n",
    "# Bound on the distance to example in norm-1\n",
    "m.addConstr(abs_diff >= x - image)\n",
    "m.addConstr(abs_diff >= -x + image)\n",
    "m.addConstr(abs_diff.sum() <= delta)\n",
    "\n",
    "pred_constr = add_predictor_constr(m, nn_regression, x, y)\n",
    "\n",
    "pred_constr.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter BestBdStop to value 0\n",
      "Set parameter BestObjStop to value 0\n",
      "Gurobi Optimizer version 10.0.1 build v10.0.1rc0 (linux64)\n",
      "\n",
      "CPU model: AMD EPYC 7402 24-Core Processor, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 48 physical cores, 96 logical processors, using up to 32 threads\n",
      "\n",
      "Optimize a model with 1679 rows, 1778 columns and 46230 nonzeros\n",
      "Model fingerprint: 0x92e40b5a\n",
      "Model has 100 general constraints\n",
      "Variable types: 1778 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-07, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [8e-04, 3e+02]\n",
      "Presolve removed 794 rows and 10 columns\n",
      "Presolve time: 0.00s\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 96 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Model is infeasible or unbounded\n",
      "Best objective -, best bound -, gap -\n"
     ]
    }
   ],
   "source": [
    "m.Params.BestBdStop = 0.0\n",
    "m.Params.BestObjStop = 0.0\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No counter example exists in neighborhood.\n"
     ]
    }
   ],
   "source": [
    "if m.ObjVal > 0.0:\n",
    "    plt.imshow(x.X.reshape((28, 28)), cmap=\"gray\")\n",
    "    x_input = torch.tensor(x.X.reshape(1, -1), dtype=torch.float32)\n",
    "    label = torch.argmax(nn_model.forward(x_input))\n",
    "    print(f\"Solution is classified as {label}\")\n",
    "else:\n",
    "    print(\"No counter example exists in neighborhood.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copyright © 2022 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfMIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "license": {
   "full_text": "# Copyright © 2022 Gurobi Optimization, LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================="
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
